{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/azibit/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:68: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gym\n",
    "import ray\n",
    "from animalai.envs.arena_config import ArenaConfig\n",
    "from animalai.envs.gym.environment import AnimalAIGym\n",
    "from ray.rllib.agents import ppo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.tune import register_env, tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnityEnvWrapper(gym.Env):\n",
    "    def __init__(self, env_config):\n",
    "        self.vector_index = env_config.vector_index\n",
    "        self.worker_index = env_config.worker_index\n",
    "        self.worker_id = env_config[\"unity_worker_id\"] + env_config.worker_index\n",
    "        self.env = AnimalAIGym(\n",
    "            environment_filename = \"/home/azibit/Downloads/AnimalAI-Olympics/examples/env/AnimalAI\",\n",
    "            worker_id = self.worker_id,\n",
    "            flatten_branched = True,\n",
    "            uint8_visual = True,\n",
    "            arenas_configurations = ArenaConfig('/home/azibit/Downloads/AnimalAI-Olympics/examples/configurations/curriculum/0.yml')\n",
    "        )\n",
    "        self.action_space = self.env.action_space\n",
    "        self.observation_space = self.env.observation_space\n",
    "        \n",
    "    def reset(self):\n",
    "        return self.env.reset()\n",
    "    \n",
    "    def step(self, action):\n",
    "        return self.env.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'env': 'unity_env',\n",
       " 'num_workers': 1,\n",
       " 'env_config': {'unity_worker_id': 52},\n",
       " 'num_gpus': 0,\n",
       " 'framework': 'torch',\n",
       " 'train_batch_size': 500}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf = {\"env\": \"unity_env\",\n",
    "            \"num_workers\": 0,\n",
    "            \"env_config\": {\n",
    "                \"unity_worker_id\": 52\n",
    "            },\n",
    "        \"num_gpus\": int(os.environ.get(\"RLLIB_NUM_GPUS\", \"0\")),\n",
    "        \"num_workers\": 1,  # parallelism\n",
    "        \"framework\": \"torch\",\n",
    "        \"train_batch_size\": 500\n",
    "       }\n",
    "conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-19 00:13:29,543\tINFO services.py:1174 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n"
     ]
    }
   ],
   "source": [
    "ray.shutdown()\n",
    "ray.init()\n",
    "\n",
    "register_env(\"unity_env\", lambda config: UnityEnvWrapper(config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.4/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.45 GiB heap, 0.0/2.2 GiB objects<br>Result logdir: /home/azibit/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name               </th><th>status  </th><th>loc  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_unity_env_d9a69_00000</td><td>RUNNING </td><td>     </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=34746)\u001b[0m WARNING:tensorflow:From /home/azibit/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:68: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=34746)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=34746)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=34746)\u001b[0m 2021-03-19 00:13:34,927\tINFO trainer.py:643 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=34745)\u001b[0m WARNING:tensorflow:From /home/azibit/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:68: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=34745)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=34745)\u001b[0m non-resource variables are not supported in the long term\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=34745)\u001b[0m Found path: /home/azibit/Downloads/AnimalAI-Olympics/examples/env/AnimalAI.x86_64\n",
      "\u001b[2m\u001b[36m(pid=34745)\u001b[0m Mono path[0] = '/home/azibit/Downloads/AnimalAI-Olympics/examples/env/AnimalAI_Data/Managed'\n",
      "\u001b[2m\u001b[36m(pid=34745)\u001b[0m Mono config path = '/home/azibit/Downloads/AnimalAI-Olympics/examples/env/AnimalAI_Data/MonoBleedingEdge/etc'\n",
      "\u001b[2m\u001b[36m(pid=34745)\u001b[0m Preloaded 'lib_burst_generated.so'\n",
      "\u001b[2m\u001b[36m(pid=34745)\u001b[0m Preloaded 'libgrpc_csharp_ext.x64.so'\n",
      "\u001b[2m\u001b[36m(pid=34745)\u001b[0m Preloaded 'ScreenSelector.so'\n",
      "\u001b[2m\u001b[36m(pid=34745)\u001b[0m Display 0 '0': 1920x1080 (primary device).\n",
      "\u001b[2m\u001b[36m(pid=34745)\u001b[0m Logging to /home/azibit/.config/unity3d/Unity Technologies/UnityEnvironment/Player.log\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=34745)\u001b[0m INFO:mlagents_envs:Connected to Unity environment with package version 0.15.0-preview and communication version 0.15.0\n",
      "\u001b[2m\u001b[36m(pid=34745)\u001b[0m INFO:mlagents_envs:Connected new brain:\n",
      "\u001b[2m\u001b[36m(pid=34745)\u001b[0m AnimalAI?team=0\n",
      "\u001b[2m\u001b[36m(pid=34745)\u001b[0m INFO:gym_unity:1 agents within environment.\n",
      "\u001b[2m\u001b[36m(pid=34745)\u001b[0m 2021-03-19 00:13:40,296\tWARNING deprecation.py:34 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=34746)\u001b[0m 2021-03-19 00:13:40,440\tWARNING deprecation.py:34 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=34746)\u001b[0m 2021-03-19 00:13:40,594\tWARNING util.py:47 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(pid=34745)\u001b[0m 2021-03-19 00:13:40,618\tWARNING deprecation.py:34 -- DeprecationWarning: `env_index` has been deprecated. Use `episode.env_id` instead. This will raise an error in the future!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_unity_env_d9a69_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-03-19_00-14-31\n",
      "  done: false\n",
      "  episode_len_mean: 9.966666666666667\n",
      "  episode_reward_max: 0.975000006146729\n",
      "  episode_reward_mean: 0.9602888968152304\n",
      "  episode_reward_min: 0.88033336866647\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 60\n",
      "  experiment_id: 41340d0296b1412cb96e4f2aa1b78dec\n",
      "  hostname: azibit-Lenovo-Y520-15IKBM\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_kl_coeff: 0.2\n",
      "        cur_lr: 5.0e-05\n",
      "        entropy: 0.3387770354747772\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.1652733027935028\n",
      "        policy_loss: 0.041499136760830876\n",
      "        total_loss: 1.3208546400070191\n",
      "        vf_explained_var: -0.20183400809764862\n",
      "        vf_loss: 1.2463008522987367\n",
      "    num_steps_sampled: 600\n",
      "    num_steps_trained: 600\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 127.0.1.1\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.556164383561647\n",
      "    ram_util_percent: 46.37808219178083\n",
      "  pid: 34746\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049439920561880915\n",
      "    mean_env_wait_ms: 5.2394866943359375\n",
      "    mean_inference_ms: 3.7077568136713466\n",
      "    mean_raw_obs_processing_ms: 0.5796340459991808\n",
      "  time_since_restore: 50.68300795555115\n",
      "  time_this_iter_s: 50.68300795555115\n",
      "  time_total_s: 50.68300795555115\n",
      "  timers:\n",
      "    learn_throughput: 13.365\n",
      "    learn_time_ms: 44893.314\n",
      "    sample_throughput: 103.771\n",
      "    sample_time_ms: 5781.961\n",
      "    update_time_ms: 2.192\n",
      "  timestamp: 1616130871\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 600\n",
      "  training_iteration: 1\n",
      "  trial_id: d9a69_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 7.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.45 GiB heap, 0.0/2.2 GiB objects<br>Result logdir: /home/azibit/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name               </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_unity_env_d9a69_00000</td><td>RUNNING </td><td>127.0.1.1:34746</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">          50.683</td><td style=\"text-align: right;\"> 600</td><td style=\"text-align: right;\">0.960289</td><td style=\"text-align: right;\">               0.975</td><td style=\"text-align: right;\">            0.880333</td><td style=\"text-align: right;\">           9.96667</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_unity_env_d9a69_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-03-19_00-15-28\n",
      "  done: true\n",
      "  episode_len_mean: 11.57\n",
      "  episode_reward_max: 0.975000006146729\n",
      "  episode_reward_mean: 0.9539866749290377\n",
      "  episode_reward_min: 0.8056666702032089\n",
      "  episodes_this_iter: 44\n",
      "  episodes_total: 104\n",
      "  experiment_id: 41340d0296b1412cb96e4f2aa1b78dec\n",
      "  hostname: azibit-Lenovo-Y520-15IKBM\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_kl_coeff: 0.30000000000000004\n",
      "        cur_lr: 5.0e-05\n",
      "        entropy: 0.35833298563957217\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.032970056682825086\n",
      "        policy_loss: -0.016580140963196755\n",
      "        total_loss: 0.017722992599010466\n",
      "        vf_explained_var: -0.19906166195869446\n",
      "        vf_loss: 0.024412114918231965\n",
      "    num_steps_sampled: 1200\n",
      "    num_steps_trained: 1200\n",
      "  iterations_since_restore: 2\n",
      "  node_ip: 127.0.1.1\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.56463414634146\n",
      "    ram_util_percent: 47.64512195121951\n",
      "  pid: 34746\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05057870001882625\n",
      "    mean_env_wait_ms: 5.322708023477851\n",
      "    mean_inference_ms: 3.8269224061316014\n",
      "    mean_raw_obs_processing_ms: 0.5595485355370255\n",
      "  time_since_restore: 107.91102528572083\n",
      "  time_this_iter_s: 57.22801733016968\n",
      "  time_total_s: 107.91102528572083\n",
      "  timers:\n",
      "    learn_throughput: 12.519\n",
      "    learn_time_ms: 47926.471\n",
      "    sample_throughput: 99.659\n",
      "    sample_time_ms: 6020.501\n",
      "    update_time_ms: 2.595\n",
      "  timestamp: 1616130928\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1200\n",
      "  training_iteration: 2\n",
      "  trial_id: d9a69_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 7.8/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.45 GiB heap, 0.0/2.2 GiB objects<br>Result logdir: /home/azibit/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name               </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_unity_env_d9a69_00000</td><td>RUNNING </td><td>127.0.1.1:34746</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         107.911</td><td style=\"text-align: right;\">1200</td><td style=\"text-align: right;\">0.953987</td><td style=\"text-align: right;\">               0.975</td><td style=\"text-align: right;\">            0.805667</td><td style=\"text-align: right;\">             11.57</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 7.8/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/8 CPUs, 0/0 GPUs, 0.0/6.45 GiB heap, 0.0/2.2 GiB objects<br>Result logdir: /home/azibit/ray_results/PPO<br>Number of trials: 1/1 (1 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name               </th><th>status    </th><th>loc  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_unity_env_d9a69_00000</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         107.911</td><td style=\"text-align: right;\">1200</td><td style=\"text-align: right;\">0.953987</td><td style=\"text-align: right;\">               0.975</td><td style=\"text-align: right;\">            0.805667</td><td style=\"text-align: right;\">             11.57</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-19 00:15:29,236\tINFO tune.py:450 -- Total run time: 116.34 seconds (115.64 seconds for the tuning loop).\n",
      "\u001b[2m\u001b[36m(pid=34745)\u001b[0m INFO:mlagents_envs:Environment shut down with return code 0.\n"
     ]
    }
   ],
   "source": [
    "result = tune.run(\"PPO\", stop = {\"timesteps_total\": 1000, \"training_iteration\": 3}, config = conf, checkpoint_at_end = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'d9a69_00000': {'episode_reward_max': 0.975000006146729,\n",
       "  'episode_reward_min': 0.8056666702032089,\n",
       "  'episode_reward_mean': 0.9539866749290377,\n",
       "  'episode_len_mean': 11.57,\n",
       "  'episodes_this_iter': 44,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [0.9643333628773689,\n",
       "    0.9536666600033641,\n",
       "    0.9576666597276926,\n",
       "    0.9683333626016974,\n",
       "    0.8656666660681367,\n",
       "    0.9683333626016974,\n",
       "    0.9656666591763496,\n",
       "    0.9683333626016974,\n",
       "    0.9683333626016974,\n",
       "    0.9683333626016974,\n",
       "    0.9656666591763496,\n",
       "    0.9470000080764294,\n",
       "    0.9616666594520211,\n",
       "    0.9510000078007579,\n",
       "    0.9150000102818012,\n",
       "    0.9696666589006782,\n",
       "    0.975000006146729,\n",
       "    0.9616666594520211,\n",
       "    0.9736666586250067,\n",
       "    0.9696666589006782,\n",
       "    0.975000006146729,\n",
       "    0.9683333626016974,\n",
       "    0.8496666671708226,\n",
       "    0.9683333626016974,\n",
       "    0.975000006146729,\n",
       "    0.8056666702032089,\n",
       "    0.9616666594520211,\n",
       "    0.9683333626016974,\n",
       "    0.975000006146729,\n",
       "    0.9683333626016974,\n",
       "    0.859000014141202,\n",
       "    0.9683333626016974,\n",
       "    0.9430000083521008,\n",
       "    0.9416666608303785,\n",
       "    0.9430000083521008,\n",
       "    0.9616666594520211,\n",
       "    0.9536666600033641,\n",
       "    0.9683333626016974,\n",
       "    0.8056666702032089,\n",
       "    0.9270000094547868,\n",
       "    0.9656666591763496,\n",
       "    0.9110000105574727,\n",
       "    0.9710000064224005,\n",
       "    0.9576666597276926,\n",
       "    0.9696666589006782,\n",
       "    0.9630000069737434,\n",
       "    0.9683333626016974,\n",
       "    0.9430000083521008,\n",
       "    0.9416666608303785,\n",
       "    0.975000006146729,\n",
       "    0.9616666594520211,\n",
       "    0.9616666594520211,\n",
       "    0.967000006698072,\n",
       "    0.9656666591763496,\n",
       "    0.88033336866647,\n",
       "    0.9683333626016974,\n",
       "    0.9710000064224005,\n",
       "    0.9643333628773689,\n",
       "    0.9510000078007579,\n",
       "    0.9590000072494149,\n",
       "    0.975000006146729,\n",
       "    0.9710000064224005,\n",
       "    0.9710000064224005,\n",
       "    0.972333362326026,\n",
       "    0.975000006146729,\n",
       "    0.9470000080764294,\n",
       "    0.9616666594520211,\n",
       "    0.975000006146729,\n",
       "    0.9683333626016974,\n",
       "    0.975000006146729,\n",
       "    0.9350000089034438,\n",
       "    0.9683333626016974,\n",
       "    0.9563333634287119,\n",
       "    0.975000006146729,\n",
       "    0.9590000072494149,\n",
       "    0.9470000080764294,\n",
       "    0.9696666589006782,\n",
       "    0.975000006146729,\n",
       "    0.9643333628773689,\n",
       "    0.9576666597276926,\n",
       "    0.9590000072494149,\n",
       "    0.975000006146729,\n",
       "    0.975000006146729,\n",
       "    0.975000006146729,\n",
       "    0.9430000083521008,\n",
       "    0.9496666602790356,\n",
       "    0.9523333637043834,\n",
       "    0.972333362326026,\n",
       "    0.9736666586250067,\n",
       "    0.9630000069737434,\n",
       "    0.9443333642557263,\n",
       "    0.9536666600033641,\n",
       "    0.9683333626016974,\n",
       "    0.9656666591763496,\n",
       "    0.9656666591763496,\n",
       "    0.9150000102818012,\n",
       "    0.9576666597276926,\n",
       "    0.9550000075250864,\n",
       "    0.945666660554707,\n",
       "    0.9496666602790356],\n",
       "   'episode_lengths': [9,\n",
       "    12,\n",
       "    11,\n",
       "    8,\n",
       "    34,\n",
       "    8,\n",
       "    9,\n",
       "    8,\n",
       "    8,\n",
       "    8,\n",
       "    9,\n",
       "    13,\n",
       "    10,\n",
       "    12,\n",
       "    21,\n",
       "    8,\n",
       "    6,\n",
       "    10,\n",
       "    7,\n",
       "    8,\n",
       "    6,\n",
       "    8,\n",
       "    38,\n",
       "    8,\n",
       "    6,\n",
       "    49,\n",
       "    10,\n",
       "    8,\n",
       "    6,\n",
       "    8,\n",
       "    35,\n",
       "    8,\n",
       "    14,\n",
       "    15,\n",
       "    14,\n",
       "    10,\n",
       "    12,\n",
       "    8,\n",
       "    49,\n",
       "    18,\n",
       "    9,\n",
       "    22,\n",
       "    7,\n",
       "    11,\n",
       "    8,\n",
       "    9,\n",
       "    8,\n",
       "    14,\n",
       "    15,\n",
       "    6,\n",
       "    10,\n",
       "    10,\n",
       "    8,\n",
       "    9,\n",
       "    30,\n",
       "    8,\n",
       "    7,\n",
       "    9,\n",
       "    12,\n",
       "    10,\n",
       "    6,\n",
       "    7,\n",
       "    7,\n",
       "    7,\n",
       "    6,\n",
       "    13,\n",
       "    10,\n",
       "    6,\n",
       "    8,\n",
       "    6,\n",
       "    16,\n",
       "    8,\n",
       "    11,\n",
       "    6,\n",
       "    10,\n",
       "    13,\n",
       "    8,\n",
       "    6,\n",
       "    9,\n",
       "    11,\n",
       "    10,\n",
       "    6,\n",
       "    6,\n",
       "    6,\n",
       "    14,\n",
       "    13,\n",
       "    12,\n",
       "    7,\n",
       "    7,\n",
       "    9,\n",
       "    14,\n",
       "    12,\n",
       "    8,\n",
       "    9,\n",
       "    9,\n",
       "    21,\n",
       "    11,\n",
       "    11,\n",
       "    14,\n",
       "    13]},\n",
       "  'sampler_perf': {'mean_env_wait_ms': 5.322708023477851,\n",
       "   'mean_raw_obs_processing_ms': 0.5595485355370255,\n",
       "   'mean_inference_ms': 3.8269224061316014,\n",
       "   'mean_action_processing_ms': 0.05057870001882625},\n",
       "  'off_policy_estimator': {},\n",
       "  'num_healthy_workers': 1,\n",
       "  'timesteps_total': 1200,\n",
       "  'timers': {'sample_time_ms': 6020.501,\n",
       "   'sample_throughput': 99.659,\n",
       "   'learn_time_ms': 47926.471,\n",
       "   'learn_throughput': 12.519,\n",
       "   'update_time_ms': 2.595},\n",
       "  'info': {'learner': {'default_policy': {'allreduce_latency': 0.0,\n",
       "     'cur_kl_coeff': 0.30000000000000004,\n",
       "     'cur_lr': 5e-05,\n",
       "     'total_loss': 0.017722992599010466,\n",
       "     'policy_loss': -0.016580140963196755,\n",
       "     'vf_loss': 0.024412114918231965,\n",
       "     'vf_explained_var': -0.19906166,\n",
       "     'kl': 0.032970056682825086,\n",
       "     'entropy': 0.35833298563957217,\n",
       "     'entropy_coeff': 0.0}},\n",
       "   'num_steps_sampled': 1200,\n",
       "   'num_steps_trained': 1200},\n",
       "  'done': True,\n",
       "  'episodes_total': 104,\n",
       "  'training_iteration': 2,\n",
       "  'experiment_id': '41340d0296b1412cb96e4f2aa1b78dec',\n",
       "  'date': '2021-03-19_00-15-28',\n",
       "  'timestamp': 1616130928,\n",
       "  'time_this_iter_s': 57.22801733016968,\n",
       "  'time_total_s': 107.91102528572083,\n",
       "  'pid': 34746,\n",
       "  'hostname': 'azibit-Lenovo-Y520-15IKBM',\n",
       "  'node_ip': '127.0.1.1',\n",
       "  'config': {'num_workers': 1,\n",
       "   'num_envs_per_worker': 1,\n",
       "   'create_env_on_driver': False,\n",
       "   'rollout_fragment_length': 200,\n",
       "   'batch_mode': 'truncate_episodes',\n",
       "   'num_gpus': 0,\n",
       "   'train_batch_size': 500,\n",
       "   'model': {'fcnet_hiddens': [256, 256],\n",
       "    'fcnet_activation': 'tanh',\n",
       "    'conv_filters': None,\n",
       "    'conv_activation': 'relu',\n",
       "    'free_log_std': False,\n",
       "    'no_final_linear': False,\n",
       "    'vf_share_layers': False,\n",
       "    'use_lstm': False,\n",
       "    'max_seq_len': 20,\n",
       "    'lstm_cell_size': 256,\n",
       "    'lstm_use_prev_action': False,\n",
       "    'lstm_use_prev_reward': False,\n",
       "    '_time_major': False,\n",
       "    'use_attention': False,\n",
       "    'attention_num_transformer_units': 1,\n",
       "    'attention_dim': 64,\n",
       "    'attention_num_heads': 1,\n",
       "    'attention_head_dim': 32,\n",
       "    'attention_memory_inference': 50,\n",
       "    'attention_memory_training': 50,\n",
       "    'attention_position_wise_mlp_dim': 32,\n",
       "    'attention_init_gru_gate_bias': 2.0,\n",
       "    'num_framestacks': 'auto',\n",
       "    'dim': 84,\n",
       "    'grayscale': False,\n",
       "    'zero_mean': True,\n",
       "    'custom_model': None,\n",
       "    'custom_model_config': {},\n",
       "    'custom_action_dist': None,\n",
       "    'custom_preprocessor': None,\n",
       "    'lstm_use_prev_action_reward': -1,\n",
       "    'framestack': True},\n",
       "   'optimizer': {},\n",
       "   'gamma': 0.99,\n",
       "   'horizon': None,\n",
       "   'soft_horizon': False,\n",
       "   'no_done_at_end': False,\n",
       "   'env_config': {'unity_worker_id': 52},\n",
       "   'env': 'unity_env',\n",
       "   'normalize_actions': False,\n",
       "   'clip_rewards': None,\n",
       "   'clip_actions': True,\n",
       "   'preprocessor_pref': 'deepmind',\n",
       "   'lr': 5e-05,\n",
       "   'monitor': False,\n",
       "   'log_level': 'WARN',\n",
       "   'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "   'ignore_worker_failures': False,\n",
       "   'log_sys_usage': True,\n",
       "   'fake_sampler': False,\n",
       "   'framework': 'torch',\n",
       "   'eager_tracing': False,\n",
       "   'explore': True,\n",
       "   'exploration_config': {'type': 'StochasticSampling'},\n",
       "   'evaluation_interval': None,\n",
       "   'evaluation_num_episodes': 10,\n",
       "   'in_evaluation': False,\n",
       "   'evaluation_config': {},\n",
       "   'evaluation_num_workers': 0,\n",
       "   'custom_eval_function': None,\n",
       "   'sample_async': False,\n",
       "   '_use_trajectory_view_api': True,\n",
       "   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "   'observation_filter': 'NoFilter',\n",
       "   'synchronize_filters': True,\n",
       "   'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "    'inter_op_parallelism_threads': 2,\n",
       "    'gpu_options': {'allow_growth': True},\n",
       "    'log_device_placement': False,\n",
       "    'device_count': {'CPU': 1},\n",
       "    'allow_soft_placement': True},\n",
       "   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "    'inter_op_parallelism_threads': 8},\n",
       "   'compress_observations': False,\n",
       "   'collect_metrics_timeout': 180,\n",
       "   'metrics_smoothing_episodes': 100,\n",
       "   'remote_worker_envs': False,\n",
       "   'remote_env_batch_wait_ms': 0,\n",
       "   'min_iter_time_s': 0,\n",
       "   'timesteps_per_iteration': 0,\n",
       "   'seed': None,\n",
       "   'extra_python_environs_for_driver': {},\n",
       "   'extra_python_environs_for_worker': {},\n",
       "   'num_cpus_per_worker': 1,\n",
       "   'num_gpus_per_worker': 0,\n",
       "   'custom_resources_per_worker': {},\n",
       "   'num_cpus_for_driver': 1,\n",
       "   'memory': 0,\n",
       "   'object_store_memory': 0,\n",
       "   'memory_per_worker': 0,\n",
       "   'object_store_memory_per_worker': 0,\n",
       "   'input': 'sampler',\n",
       "   'input_evaluation': ['is', 'wis'],\n",
       "   'postprocess_inputs': False,\n",
       "   'shuffle_buffer_size': 0,\n",
       "   'output': None,\n",
       "   'output_compress_columns': ['obs', 'new_obs'],\n",
       "   'output_max_file_size': 67108864,\n",
       "   'multiagent': {'policies': {},\n",
       "    'policy_mapping_fn': None,\n",
       "    'policies_to_train': None,\n",
       "    'observation_fn': None,\n",
       "    'replay_mode': 'independent',\n",
       "    'count_steps_by': 'env_steps'},\n",
       "   'logger_config': None,\n",
       "   'replay_sequence_length': 1,\n",
       "   'use_critic': True,\n",
       "   'use_gae': True,\n",
       "   'lambda': 1.0,\n",
       "   'kl_coeff': 0.2,\n",
       "   'sgd_minibatch_size': 128,\n",
       "   'shuffle_sequences': True,\n",
       "   'num_sgd_iter': 30,\n",
       "   'lr_schedule': None,\n",
       "   'vf_loss_coeff': 1.0,\n",
       "   'entropy_coeff': 0.0,\n",
       "   'entropy_coeff_schedule': None,\n",
       "   'clip_param': 0.3,\n",
       "   'vf_clip_param': 10.0,\n",
       "   'grad_clip': None,\n",
       "   'kl_target': 0.01,\n",
       "   'simple_optimizer': True,\n",
       "   '_fake_gpus': False,\n",
       "   'vf_share_layers': -1},\n",
       "  'time_since_restore': 107.91102528572083,\n",
       "  'timesteps_since_restore': 0,\n",
       "  'iterations_since_restore': 2,\n",
       "  'perf': {'cpu_util_percent': 33.56463414634146,\n",
       "   'ram_util_percent': 47.64512195121951},\n",
       "  'trial_id': 'd9a69_00000',\n",
       "  'experiment_tag': '0'}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.rllib.agents.ppo import PPOTrainer\n",
    "\n",
    "ray.shutdown()\n",
    "ray.init()\n",
    "\n",
    "register_env(\"unity_env\", lambda config: UnityEnvWrapper(config))\n",
    "res = tune.run(PPOTrainer, config=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
